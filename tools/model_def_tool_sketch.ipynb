{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_jl_files (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Functions to find all the Julia files in a directory and subdirectories\n",
    "function filter_jl_files(dir_list::Vector{String})\n",
    "    \"\"\"Filter a list of filenames into a list of Julia files and a list of non-Julia files\"\"\"\n",
    "    jl_files = filter(x -> endswith(x, \".jl\"), dir_list)\n",
    "    non_jl_files = setdiff(dir_list, jl_files)\n",
    "    return jl_files, non_jl_files\n",
    "end\n",
    "\n",
    "function add_filepaths!(filepaths::Dict{String, String}, dir_path::String, dir_list::Vector{String})\n",
    "    \"\"\"Add a list of filepaths to a dictionary\"\"\"\n",
    "    for file in dir_list\n",
    "        filepaths[file] = joinpath(dir_path, file)\n",
    "    end\n",
    "end\n",
    "\n",
    "function find_jl_files(dir_path::String)\n",
    "    \"\"\"Find all Julia files in a directory and subdirectories\"\"\"\n",
    "    filepaths = Dict{String, String}()\n",
    "    jl_files, non_jl_files = filter_jl_files(readdir(dir_path))\n",
    "    add_filepaths!(filepaths, dir_path, jl_files)\n",
    "    new_dirs = filter(x -> isdir(joinpath(dir_path, x)), non_jl_files)\n",
    "    for new_dir in new_dirs\n",
    "        merge!(filepaths, find_jl_files(joinpath(dir_path, new_dir)))\n",
    "    end\n",
    "    return filepaths\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_filestrings (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Functions to read a Julia file, clean it, and return it as a long string\n",
    "function clean_file(dir_path::String)\n",
    "    \"\"\"\n",
    "        filestring = clean_file(dir_path::String)\n",
    "\n",
    "    Read a Julia file line by line,\n",
    "    removing all comments and doc strings,\n",
    "    then appending each line to a string with a space\n",
    "    \"\"\"\n",
    "    open(dir_path, \"r\") do file\n",
    "        filestring = \"\"\n",
    "        long_comment = false\n",
    "        for line in eachline(file)\n",
    "            # Check for doc strings and ignore them\n",
    "            if contains(line, \"\"\"\\\"\\\"\\\"\"\"\")\n",
    "                long_comment = !long_comment\n",
    "            end\n",
    "            if long_comment\n",
    "                continue\n",
    "            else \n",
    "                # Remove comments\n",
    "                if !startswith(strip(line), \"#\") && line != \"\"\n",
    "                    # Remove end-of-line commments\n",
    "                    line = split(line, \"#\")[1]\n",
    "                    # Remove tabs\n",
    "                    line = replace(line, \"\\t\" => \" \")\n",
    "                    # Make all one line, but add space to avoid concatenating words\n",
    "                    filestring = string(filestring, \" \", line)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        return filestring\n",
    "    end\n",
    "end\n",
    "\n",
    "function make_filestrings(filepath::Dict{String, String})\n",
    "    \"\"\"Make a dictionary of filestrings from a dictionary of filepaths\"\"\"\n",
    "    filestrings = Dict{String, String}()\n",
    "    for (filename, filepath) in filepaths\n",
    "        filestrings[filename] = clean_file(filepath)\n",
    "    end\n",
    "    return filestrings\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_feature_creation! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Functions to find the names and creation-file of model features from a filestring\n",
    "function extract_feature_name(filestring::AbstractString, filter_prefix::AbstractString)\n",
    "    \"\"\"Extract the name of a model feature from a file-substring\"\"\"\n",
    "    x = split(filestring, \",\")\n",
    "    # Try to extract the name based on a prefix\n",
    "    x2 = split(x[2], \" \")\n",
    "    x2 = filter(x -> startswith(x, filter_prefix), x2)\n",
    "    if !isempty(x2)\n",
    "        x = x2[1]\n",
    "    else\n",
    "        x = x[2]\n",
    "    end\n",
    "    # Remove any indexing\n",
    "    if contains(x, \"[\")\n",
    "        x = split(x, \"[\")[1]\n",
    "    end\n",
    "    # Remove whitespace\n",
    "    return strip(x)\n",
    "end\n",
    "\n",
    "function find_feature_names(filestring::String, filter_string::String)\n",
    "    \"\"\"Create a list of the names of all the model feature of a given type, from a filestring\"\"\"\n",
    "    cases = split(filestring, filter_string)\n",
    "    feature_names = Vector{String}()\n",
    "    filter_prefix = string(filter_string[2])\n",
    "    for i in 2:length(cases)\n",
    "        push!(feature_names, extract_feature_name(cases[i], filter_prefix))\n",
    "    end\n",
    "    return feature_names\n",
    "end\n",
    "\n",
    "function find_feature_creation!(feature_results::Dict{String, Any}, filestrings::Dict{String, String}, feature_name::String)\n",
    "    \"\"\"Find the files in which a set of features is created\"\"\"\n",
    "    for (filename, filestring) in filestrings\n",
    "        new_feature_names = find_feature_names(filestring, feature_name)\n",
    "        for new_name in new_feature_names\n",
    "            if !haskey(feature_results, new_name)\n",
    "                feature_results[new_name] = Dict{String, Any}()\n",
    "            end\n",
    "            feature_results[new_name][\"created\"] = filename\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_feature_accesses! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Functions to find where each model feature is accessed\n",
    "function check_access(filestrings::Dict{String, String}, feature_names::Vector{String})\n",
    "    \"\"\"Check if features are accessed in a set of files, using filestrings\"\"\"\n",
    "    file_accesses = Dict{String, Vector{String}}()\n",
    "    for (filename, filestring) in filestrings\n",
    "        file_accesses[filename] = Vector{String}()\n",
    "        for feature_name in feature_names\n",
    "            if contains(filestring, feature_name)\n",
    "                push!(file_accesses[filename], feature_name)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return file_accesses\n",
    "end\n",
    "\n",
    "function push_accesses!(feature_results::Dict{String, Any}, accesses::Dict{String, Vector{String}})\n",
    "    \"\"\"Push a list of features accesses to a feature result dictionary\"\"\"\n",
    "    for (filename, feature_names) in accesses\n",
    "        for feature_name in feature_names\n",
    "            if !haskey(feature_results[feature_name], \"accessed\")\n",
    "                feature_results[feature_name][\"accessed\"] = Vector{String}()\n",
    "            end\n",
    "            push!(feature_results[feature_name][\"accessed\"], filename)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function find_feature_accesses!(feature_results::Dict{String, Any}, filestrings::Dict{String, String})\n",
    "    \"\"\"Find the files in which a set of features is accessed\"\"\"\n",
    "    accesses = check_access(filestrings, collect(keys(feature_results)))\n",
    "    push_accesses!(feature_results, accesses)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "write_2_file (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Functions to turn search_results into a Markdown table\n",
    "function make_table_header(headers::Set{String}, feature_type::String)\n",
    "    fun_headers = copy(headers)\n",
    "    table_header = \"|$(feature_type) name\"\n",
    "    table_divider = \"|:-\"\n",
    "    if \"created\" in fun_headers # Later we can automate this using the features_to_search superdetails\n",
    "        table_header = string(table_header, \"|created\")\n",
    "        table_divider = string(table_divider, \"|:-\")\n",
    "        delete!(fun_headers, \"created\")\n",
    "    end    \n",
    "    for header in fun_headers\n",
    "        table_header = string(table_header, \"|\", header)\n",
    "        table_divider = string(table_divider, \"|\", \":-\")\n",
    "    end\n",
    "    table_header = string(table_header, \"|\")\n",
    "    table_divider = string(table_divider, \"|\")\n",
    "    return table_header, table_divider\n",
    "end\n",
    "\n",
    "function make_table_row(feature_name::String, feature_results::Dict{String, Any}, headers::Set{String})\n",
    "    table_row = \"|$(feature_name)\"\n",
    "    fun_headers = copy(headers)\n",
    "    if \"created\" in fun_headers\n",
    "        table_row = string(table_row, \"|\", feature_results[\"created\"])\n",
    "        delete!(fun_headers, \"created\")\n",
    "    end\n",
    "    for header in fun_headers\n",
    "        table_row = string(table_row, \"|\", join(feature_results[header], \", \"))\n",
    "    end\n",
    "    table_row = string(table_row, \"|\")\n",
    "    return table_row\n",
    "end\n",
    "\n",
    "function features_2_markdown(feature_results::Dict{String, Any}, feature_type::String, headers::Set{String})\n",
    "    md_table = Vector{String}()\n",
    "    push!(md_table, \"## $(feature_type)s\")\n",
    "    table_header, table_divider = make_table_header(headers, feature_type)\n",
    "    push!(md_table, table_header)\n",
    "    push!(md_table, table_divider)\n",
    "    sorted_names = sort(collect(keys(feature_results)))\n",
    "    for name in sorted_names\n",
    "        push!(md_table, make_table_row(name, feature_results[name], headers))\n",
    "    end\n",
    "    return md_table\n",
    "end\n",
    "\n",
    "function write_2_file(filename::String, md_table::Vector{String})\n",
    "    open(filename, \"w\") do f\n",
    "        for line in md_table\n",
    "            write(f, string(line, \"\\n\"))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function write_2_file(filename::String, md_table::Vector{String}, open_mode::String)\n",
    "    open(filename, open_mode) do f\n",
    "        for line in md_table\n",
    "            write(f, string(line, \"\\n\"))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This finds all the variables and expressions, and prints them as a markdown table\n",
    "\n",
    "# Get all Julia files in the src directory\n",
    "src_path = joinpath(dirname(pwd()), \"src\")\n",
    "filepaths = find_jl_files(src_path)\n",
    "\n",
    "outpath = joinpath(pwd(), \"model_table.md\")\n",
    "open(outpath, \"w\") do io\n",
    "    println(io, \"# Model Variables and Expressions\")\n",
    "end\n",
    "\n",
    "# Clean all Julia files and return them as strings\n",
    "filestrings = make_filestrings(filepaths)\n",
    "\n",
    "# Create a dictionary of all the model features we'd like to search for, and the details of interest\n",
    "features_to_search = Dict(\n",
    "    \"var\" => Dict(\"filter_string\" => \"@variable\", \"table_name\" => \"Variable\", \"details\" => [\"created\", \"accessed\"], \"superdetails\" => [\"created\"]),\n",
    "    \"exp\" => Dict(\"filter_string\" => \"@expression\", \"table_name\" => \"Expression\", \"details\" => [\"created\", \"accessed\"], \"superdetails\" => [\"created\"])\n",
    ")\n",
    "\n",
    "# Create dictionary to hold search results\n",
    "# We could be more specific and make the last Dict{String, String||List}, but this is safer\n",
    "search_results = Dict{String, Dict{String, Any}}()\n",
    "for (search_name, search_details) in features_to_search\n",
    "    search_results[search_name] = Dict{String, Dict{String, Any}}()\n",
    "end\n",
    "\n",
    "# Our dict of results is not ordered, so we specify that here\n",
    "print_order = Vector{String}([\"var\", \"exp\"])\n",
    "\n",
    "# Find the file in which each feature is created\n",
    "for search_name in print_order\n",
    "    search_details = features_to_search[search_name]\n",
    "    find_feature_creation!(search_results[search_name], filestrings, search_details[\"filter_string\"])\n",
    "    find_feature_accesses!(search_results[search_name], filestrings)\n",
    "    md_table = features_2_markdown(search_results[search_name], search_details[\"table_name\"], Set(search_details[\"details\"]))\n",
    "    write_2_file(outpath, md_table, \"a\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_functions (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function extract_function_names_and_args(filestring::String)\n",
    "    \"\"\"Extract function names and arguments from a filestring\"\"\"\n",
    "    function_args = Dict{String, Vector{String}}()\n",
    "    filesubstrings = split(filestring, \"function \")\n",
    "    filesubstrings = filesubstrings[2:end]\n",
    "    for substring in filesubstrings\n",
    "        substring = split(substring, \"(\")\n",
    "        function_name = substring[1]\n",
    "        function_arg = split(split(substring[2], \")\")[1], \", \")\n",
    "        function_args[function_name] = function_arg\n",
    "    end\n",
    "    return function_args\n",
    "end\n",
    "\n",
    "function find_functions(filestrings::Dict{String, String})\n",
    "    \"\"\"Find all functions in a set of filestrings\"\"\"\n",
    "    functions_dict = Dict{String, Dict{String, Vector{String}}}()\n",
    "    for (filename, filestring) in filestrings\n",
    "        functions_dict[filename] = extract_function_names_and_args(filestring)\n",
    "    end\n",
    "    return functions_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Dict{String, Vector{String}}} with 145 entries:\n",
       "  \"h2_production_commit.jl\"          => Dict(\"h2_production_commit\"=>[\"EP::Mode…\n",
       "  \"write_reserve_margin_revenue.jl\"  => Dict(\"write_reserve_margin_revenue\"=>[\"…\n",
       "  \"load_co2_cap.jl\"                  => Dict(\"load_co2_cap\"=>[\"setup::Dict\", \"p…\n",
       "  \"flexible_demand.jl\"               => Dict(\"flexible_demand\"=>[\"EP::Model\", \"…\n",
       "  \"investment_discharge.jl\"          => Dict(\"investment_discharge\"=>[\"EP::Mode…\n",
       "  \"write_reg.jl\"                     => Dict(\"write_reg\"=>[\"path::AbstractStrin…\n",
       "  \"write_time_weights.jl\"            => Dict(\"write_time_weights\"=>[\"path::Abst…\n",
       "  \"load_inputs.jl\"                   => Dict(\"load_inputs\"=>[\"setup::Dict,path:…\n",
       "  \"emissions_power.jl\"               => Dict(\"emissions_power\"=>[\"EP::Model\", \"…\n",
       "  \"load_period_map.jl\"               => Dict(\"load_period_map\"=>[\"setup::Dict,p…\n",
       "  \"h2_pipeline.jl\"                   => Dict(\"h2_pipeline\"=>[\"EP::Model\", \"inpu…\n",
       "  \"load_h2_g2p_variability.jl\"       => Dict(\"load_h2_g2p_variability\"=>[\"setup…\n",
       "  \"write_curtailment.jl\"             => Dict(\"write_curtailment\"=>[\"path::Abstr…\n",
       "  \"write_h2_pipeline_expansion.jl\"   => Dict(\"write_h2_pipeline_expansion\"=>[\"p…\n",
       "  \"h2_production_all.jl\"             => Dict(\"h2_production_all\"=>[\"EP::Model\",…\n",
       "  \"load_energy_share_requirement.jl\" => Dict(\"load_energy_share_requirement\"=>[…\n",
       "  \"write_charge.jl\"                  => Dict(\"write_charge\"=>[\"path::AbstractSt…\n",
       "  \"write_h2_truck_flow.jl\"           => Dict(\"write_h2_truck_flow\"=>[\"path::Abs…\n",
       "  \"discharge.jl\"                     => Dict(\"discharge\"=>[\"EP::Model\", \"inputs…\n",
       "  ⋮                                  => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "functions_dict = find_functions(filestrings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
